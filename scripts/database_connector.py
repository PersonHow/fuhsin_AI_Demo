#!/usr/bin/env python3
"""
å¤šè³‡æ–™åº«é€£æ¥å™¨ - ä¸»å‹•å¾å„ç¨®è³‡æ–™åº«æ‹‰å–è³‡æ–™
å–ä»£åŸæœ¬çš„è¢«å‹•ç­‰å¾… .sql æª”æ¡ˆ
"""

import os
import time
import yaml
from sqlalchemy import create_engine, text
import pandas as pd
from datetime import datetime
import hashlib
import json
import requests

class DatabaseConnector:
    def __init__(self):
        self.engines = {}
        self.init_connections()
        
    def init_connections(self):
        """åˆå§‹åŒ–æ‰€æœ‰è³‡æ–™åº«é€£æ¥"""
        
        # MySQL é€£æ¥
        if os.getenv('MYSQL_HOST'):
            mysql_url = (
                f"mysql+pymysql://{os.getenv('MYSQL_USER')}:"
                f"{os.getenv('MYSQL_PASSWORD')}@"
                f"{os.getenv('MYSQL_HOST')}:{os.getenv('MYSQL_PORT')}"
            )
            self.engines['mysql'] = create_engine(mysql_url)
            print(f"âœ“ é€£æ¥ MySQL: {os.getenv('MYSQL_HOST')}")
        
        # PostgreSQL é€£æ¥
        if os.getenv('PG_HOST'):
            pg_url = (
                f"postgresql://{os.getenv('PG_USER')}:"
                f"{os.getenv('PG_PASSWORD')}@"
                f"{os.getenv('PG_HOST')}:{os.getenv('PG_PORT')}"
            )
            self.engines['postgres'] = create_engine(pg_url)
            print(f"âœ“ é€£æ¥ PostgreSQL: {os.getenv('PG_HOST')}")
    
    def get_databases(self, engine_type):
        """å–å¾—æ‰€æœ‰è³‡æ–™åº«æ¸…å–®"""
        if engine_type == 'mysql':
            query = "SHOW DATABASES"
        elif engine_type == 'postgres':
            query = "SELECT datname FROM pg_database WHERE datistemplate = false"
        
        with self.engines[engine_type].connect() as conn:
            result = conn.execute(text(query))
            return [row[0] for row in result]
    
    def get_tables(self, engine_type, database):
        """å–å¾—æŒ‡å®šè³‡æ–™åº«çš„æ‰€æœ‰è¡¨"""
        if engine_type == 'mysql':
            query = f"""
                SELECT table_name 
                FROM information_schema.tables 
                WHERE table_schema = '{database}'
            """
        elif engine_type == 'postgres':
            query = f"""
                SELECT tablename 
                FROM pg_tables 
                WHERE schemaname = 'public'
            """
        
        # å»ºç«‹åŒ…å«è³‡æ–™åº«åç¨±çš„é€£æ¥
        engine_url = str(self.engines[engine_type].url)
        if engine_type == 'mysql':
            engine_url = f"{engine_url}/{database}"
        elif engine_type == 'postgres':
            engine_url = f"{engine_url}/{database}"
        
        temp_engine = create_engine(engine_url)
        with temp_engine.connect() as conn:
            result = conn.execute(text(query))
            return [row[0] for row in result]
    
    def sync_table(self, engine_type, database, table, last_sync=None):
        """åŒæ­¥å–®ä¸€è¡¨åˆ° Elasticsearch"""
        print(f"ğŸ“Š åŒæ­¥ {engine_type}.{database}.{table}")
        
        # å»ºç«‹æŸ¥è©¢
        if last_sync:
            # å¢é‡åŒæ­¥ï¼ˆå‡è¨­æœ‰ updated_at æ¬„ä½ï¼‰
            query = f"""
                SELECT * FROM {table} 
                WHERE updated_at > '{last_sync}'
            """
        else:
            # å…¨é‡åŒæ­¥
            query = f"SELECT * FROM {table}"
        
        # è®€å–è³‡æ–™
        engine_url = f"{str(self.engines[engine_type].url)}/{database}"
        temp_engine = create_engine(engine_url)
        
        df = pd.read_sql(query, temp_engine)
        
        # è½‰æ›ç‚º Elasticsearch æ–‡æª”
        documents = []
        for idx, row in df.iterrows():
            doc = {
                "@timestamp": datetime.utcnow().isoformat(),
                "source": {
                    "system": engine_type,
                    "database": database,
                    "table": table
                },
                "data": row.to_dict()
            }
            
            # ç”Ÿæˆæ–‡æª” ID
            doc_id = hashlib.sha256(
                f"{engine_type}:{database}:{table}:{idx}".encode()
            ).hexdigest()
            
            documents.append((doc_id, doc))
        
        # ç™¼é€åˆ° Elasticsearch
        self.index_to_elasticsearch(
            f"db-{engine_type}-{database}-{table}",
            documents
        )
        
        return len(documents)
    
    def index_to_elasticsearch(self, index_name, documents):
        """æ‰¹é‡ç´¢å¼•åˆ° Elasticsearch"""
        # ... (ä½¿ç”¨åŸæœ¬çš„ bulk index é‚è¼¯)
        pass

def main():
    connector = DatabaseConnector()
    
    # è®€å–åŒæ­¥é…ç½®
    with open('/config/mapping.yaml', 'r') as f:
        config = yaml.safe_load(f)
    
    while True:
        for source in config['sources']:
            engine_type = source['type']
            databases = source.get('databases', connector.get_databases(engine_type))
            
            for db in databases:
                tables = source.get('tables', connector.get_tables(engine_type, db))
                
                for table in tables:
                    try:
                        count = connector.sync_table(engine_type, db, table)
                        print(f"âœ“ åŒæ­¥ {count} ç­†è³‡æ–™")
                    except Exception as e:
                        print(f"âœ— åŒæ­¥å¤±æ•— {db}.{table}: {e}")
        
        print(f"ğŸ’¤ ç­‰å¾… {os.getenv('SYNC_INTERVAL', 60)} ç§’...")
        time.sleep(int(os.getenv('SYNC_INTERVAL', 60)))

if __name__ == "__main__":
    main()
