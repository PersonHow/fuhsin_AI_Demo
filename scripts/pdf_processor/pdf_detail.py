#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PDF è¡¨å–®è§£æå™¨ - è©³ç´°è¨»è§£ç‰ˆ
å°ˆé–€è™•ç†ç¦èˆˆå·¥æ¥­çš„æŠ€è¡“æ–‡ä»¶è¡¨å–®
"""

import pdfplumber
import pandas as pd
from typing import Dict, List, Optional, Tuple
import re
import logging

logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

class DetailedPDFTableExtractor:
    """
    PDF è¡¨å–®è§£æå™¨ - é‡å°ç¦èˆˆå·¥æ¥­æ–‡ä»¶å„ªåŒ–
    
    PDF è§£æåŸç†ï¼š
    1. PDF æ˜¯å‘é‡æ ¼å¼ï¼Œæ–‡å­—å’Œè¡¨æ ¼æ˜¯ä»¥åº§æ¨™å½¢å¼å­˜å„²
    2. pdfplumber æœƒåˆ†ææ–‡å­—çš„ä½ç½®é—œä¿‚ä¾†è­˜åˆ¥è¡¨æ ¼
    3. é€šéè¡Œåˆ—å°é½Šä¾†é‡å»ºè¡¨æ ¼çµæ§‹
    """
    
    def __init__(self):
        # å®šç¾©ç¦èˆˆæ–‡ä»¶çš„ç‰¹å®šæ¬„ä½åç¨±ï¼ˆç”¨æ–¼è­˜åˆ¥è¡¨æ ¼ï¼‰
        self.fuhsin_table_headers = {
            # è¨­è®Šé€šçŸ¥å–®çš„æ¬„ä½
            'ecn': [
                'ç°½æ ¸äººå“¡', 'ç°½æ ¸æ™‚é–“', 'ç°½æ ¸å…§å®¹',
                'å“ä¿èª²', 'è£½é€ èª²', 'å€‰å„²èª²',
                'è¨­è®Šå‰', 'è¨­è®Šå¾Œ', 'èªªæ˜'
            ],
            # ç”¢å“è¦æ ¼è¡¨çš„æ¬„ä½
            'spec': [
                'å“è™Ÿ', 'å“å', 'è¦æ ¼', 'æè³ª', 'è¡¨é¢è™•ç†',
                'æ•¸é‡', 'å–®ä½', 'å‚™è¨»', 'åœ–è™Ÿ'
            ],
            # DFMEA è¡¨æ ¼æ¬„ä½
            'dfmea': [
                'å¤±æ•ˆæ¨¡å¼', 'å¤±æ•ˆåŸå› ', 'å¤±æ•ˆå½±éŸ¿',
                'åš´é‡åº¦', 'ç™¼ç”Ÿåº¦', 'åµæ¸¬åº¦', 'RPN'
            ],
            # å®¢è¨´å–®æ¬„ä½
            'complaint': [
                'å®¢æˆ¶åç¨±', 'æŠ±æ€¨å…§å®¹', 'åŸå› åˆ†æ',
                'çŸ¯æ­£æªæ–½', 'é é˜²æªæ–½', 'çµæ¡ˆæ—¥æœŸ'
            ]
        }
    
    def extract_with_detailed_explanation(self, pdf_path: str) -> Dict:
        """
        ä¸»è§£æå‡½æ•¸ - é™„è©³ç´°èªªæ˜
        
        Returns:
            åŒ…å«è§£æçµæœå’Œéç¨‹èªªæ˜çš„å­—å…¸
        """
        results = {
            'tables': [],
            'forms': [],
            'text_blocks': [],
            'extraction_log': []
        }
        
        try:
            with pdfplumber.open(pdf_path) as pdf:
                logger.info(f"ğŸ“– é–‹å•Ÿ PDF: {pdf_path}")
                logger.info(f"   é æ•¸: {len(pdf.pages)}")
                
                for page_num, page in enumerate(pdf.pages, 1):
                    logger.info(f"\n========== ç¬¬ {page_num} é  ==========")
                    
                    # ====== æ­¥é©Ÿ 1: åˆ†æé é¢ä½ˆå±€ ======
                    self._analyze_page_layout(page, results)
                    
                    # ====== æ­¥é©Ÿ 2: æå–è¡¨æ ¼ ======
                    tables = self._extract_tables_with_explanation(page, page_num, results)
                    
                    # ====== æ­¥é©Ÿ 3: æå–è¡¨å–®è³‡æ–™ ======
                    forms = self._extract_form_fields(page, page_num, results)
                    
                    # ====== æ­¥é©Ÿ 4: æå–æ–‡å­—å€å¡Š ======
                    text_blocks = self._extract_text_blocks(page, page_num, results)
                    
        except Exception as e:
            logger.error(f"âŒ è§£æéŒ¯èª¤: {e}")
            results['extraction_log'].append(f"éŒ¯èª¤: {str(e)}")
        
        return results
    
    def _analyze_page_layout(self, page, results: Dict):
        """
        æ­¥é©Ÿ 1: åˆ†æé é¢ä½ˆå±€
        
        åŸç†ï¼š
        - PDF é é¢æœ‰é‚Šç•Œæ¡† (bounding box)
        - æ¯å€‹æ–‡å­—ã€ç·šæ¢éƒ½æœ‰ x,y åº§æ¨™
        - é€šéåˆ†æåº§æ¨™åˆ†å¸ƒå¯ä»¥è­˜åˆ¥ç‰ˆé¢é…ç½®
        """
        # å–å¾—é é¢å°ºå¯¸
        width = page.width
        height = page.height
        
        logger.info(f"ğŸ“ é é¢å°ºå¯¸: {width:.1f} x {height:.1f} points")
        logger.info(f"   (1 point = 1/72 inch)")
        
        # åˆ†ææ–‡å­—å¯†åº¦åˆ†å¸ƒ
        chars = page.chars  # æ‰€æœ‰å­—ç¬¦åŠå…¶ä½ç½®
        if chars:
            # è¨ˆç®—æ–‡å­—åœ¨é é¢ä¸Šçš„åˆ†å¸ƒ
            x_coords = [c['x0'] for c in chars]
            y_coords = [c['top'] for c in chars]
            
            # æ‰¾å‡ºä¸»è¦çš„æ–‡å­—å€åŸŸ
            left_margin = min(x_coords)
            right_margin = max(x_coords)
            top_margin = min(y_coords)
            bottom_margin = max(y_coords)
            
            logger.info(f"ğŸ“ æ–‡å­—å€åŸŸ:")
            logger.info(f"   å·¦é‚Šç•Œ: {left_margin:.1f}")
            logger.info(f"   å³é‚Šç•Œ: {right_margin:.1f}")
            logger.info(f"   ä¸Šé‚Šç•Œ: {top_margin:.1f}")
            logger.info(f"   ä¸‹é‚Šç•Œ: {bottom_margin:.1f}")
            
            results['extraction_log'].append(
                f"é é¢æ–‡å­—å€åŸŸ: ({left_margin:.1f}, {top_margin:.1f}) åˆ° ({right_margin:.1f}, {bottom_margin:.1f})"
            )
    
    def _extract_tables_with_explanation(self, page, page_num: int, results: Dict) -> List[pd.DataFrame]:
        """
        æ­¥é©Ÿ 2: æå–è¡¨æ ¼ - è©³ç´°è§£é‡‹ç‰ˆ
        
        pdfplumber è¡¨æ ¼è­˜åˆ¥åŸç†ï¼š
        1. å°‹æ‰¾å‚ç›´å’Œæ°´å¹³ç·šæ¢
        2. ç·šæ¢äº¤å‰å½¢æˆæ ¼å­
        3. å°‡æ–‡å­—åˆ†é…åˆ°å°æ‡‰çš„æ ¼å­ä¸­
        """
        extracted_tables = []
        
        # ä½¿ç”¨ä¸åŒçš„è¡¨æ ¼æå–ç­–ç•¥
        strategies = [
            {
                'name': 'æ˜ç¢ºç·šæ¢ç­–ç•¥',
                'settings': {
                    "vertical_strategy": "lines",      # ä½¿ç”¨ç·šæ¢è­˜åˆ¥å‚ç›´é‚Šç•Œ
                    "horizontal_strategy": "lines",    # ä½¿ç”¨ç·šæ¢è­˜åˆ¥æ°´å¹³é‚Šç•Œ
                    "explicit_vertical_lines": [],     # å¯æŒ‡å®šé¡å¤–çš„å‚ç›´ç·š
                    "explicit_horizontal_lines": [],   # å¯æŒ‡å®šé¡å¤–çš„æ°´å¹³ç·š
                }
            },
            {
                'name': 'æ–‡å­—å°é½Šç­–ç•¥',
                'settings': {
                    "vertical_strategy": "text",       # ä½¿ç”¨æ–‡å­—é‚Šç·£è­˜åˆ¥å‚ç›´é‚Šç•Œ
                    "horizontal_strategy": "text",     # ä½¿ç”¨æ–‡å­—é‚Šç·£è­˜åˆ¥æ°´å¹³é‚Šç•Œ
                    "snap_tolerance": 3,              # å°é½Šå®¹å·®ï¼ˆé»ï¼‰
                    "join_tolerance": 3,              # é€£æ¥å®¹å·®ï¼ˆé»ï¼‰
                    "edge_min_length": 3,             # æœ€å°é‚Šç·£é•·åº¦
                    "min_words_vertical": 1,          # å‚ç›´æœ€å°‘æ–‡å­—æ•¸
                    "min_words_horizontal": 1,        # æ°´å¹³æœ€å°‘æ–‡å­—æ•¸
                }
            }
        ]
        
        for strategy in strategies:
            logger.info(f"\nğŸ” å˜—è©¦ç­–ç•¥: {strategy['name']}")
            
            try:
                # ä½¿ç”¨ pdfplumber çš„ find_tables æ–¹æ³•
                # é€™å€‹æ–¹æ³•æœƒè¿”å› Table ç‰©ä»¶åˆ—è¡¨
                tables = page.find_tables(table_settings=strategy['settings'])
                
                if tables:
                    logger.info(f"   âœ… æ‰¾åˆ° {len(tables)} å€‹è¡¨æ ¼")
                    
                    for i, table in enumerate(tables):
                        # å–å¾—è¡¨æ ¼çš„é‚Šç•Œæ¡†
                        bbox = table.bbox  # (x0, top, x1, bottom)
                        logger.info(f"   è¡¨æ ¼ {i+1} ä½ç½®: {bbox}")
                        
                        # æå–è¡¨æ ¼è³‡æ–™
                        data = table.extract()
                        
                        # åˆ†æè¡¨æ ¼çµæ§‹
                        if data:
                            rows = len(data)
                            cols = len(data[0]) if data[0] else 0
                            logger.info(f"   è¡¨æ ¼ {i+1} å°ºå¯¸: {rows} è¡Œ x {cols} åˆ—")
                            
                            # æª¢æŸ¥æ˜¯å¦ç‚ºç¦èˆˆç‰¹å®šè¡¨æ ¼é¡å‹
                            table_type = self._identify_table_type(data)
                            if table_type:
                                logger.info(f"   ğŸ“Š è­˜åˆ¥ç‚º: {table_type} è¡¨æ ¼")
                                
                                # æ ¹æ“šè¡¨æ ¼é¡å‹é€²è¡Œç‰¹æ®Šè™•ç†
                                processed_data = self._process_fuhsin_table(data, table_type)
                                
                                # è½‰æ›ç‚º DataFrame
                                df = self._create_dataframe(processed_data, table_type)
                                extracted_tables.append(df)
                                
                                # è¨˜éŒ„è©³ç´°è³‡è¨Š
                                results['tables'].append({
                                    'page': page_num,
                                    'type': table_type,
                                    'bbox': bbox,
                                    'shape': (rows, cols),
                                    'data': df.to_dict()
                                })
                                
                                # è§£é‡‹æå–çš„å…§å®¹
                                self._explain_table_content(df, table_type, results)
                else:
                    logger.info(f"   âŒ æœªæ‰¾åˆ°è¡¨æ ¼")
                    
            except Exception as e:
                logger.warning(f"   âš ï¸ ç­–ç•¥å¤±æ•—: {e}")
        
        return extracted_tables
    
    def _identify_table_type(self, data: List[List]) -> Optional[str]:
        """
        è­˜åˆ¥è¡¨æ ¼é¡å‹
        
        æ–¹æ³•ï¼š
        1. æª¢æŸ¥ç¬¬ä¸€è¡Œï¼ˆé€šå¸¸æ˜¯æ¨™é¡Œï¼‰
        2. æ¯”å°å·²çŸ¥çš„ç¦èˆˆè¡¨æ ¼æ ¼å¼
        3. è¨ˆç®—ç›¸ä¼¼åº¦åˆ†æ•¸
        """
        if not data or not data[0]:
            return None
        
        # å–å¾—ç¬¬ä¸€è¡Œä½œç‚ºæ½›åœ¨æ¨™é¡Œ
        first_row = [str(cell).strip() if cell else '' for cell in data[0]]
        
        logger.debug(f"   ç¬¬ä¸€è¡Œå…§å®¹: {first_row}")
        
        # èˆ‡å·²çŸ¥è¡¨æ ¼é¡å‹æ¯”å°
        for table_type, headers in self.fuhsin_table_headers.items():
            # è¨ˆç®—åŒ¹é…åˆ†æ•¸
            matches = sum(1 for header in headers if any(header in cell for cell in first_row))
            
            if matches >= len(headers) * 0.3:  # 30% åŒ¹é…å³èªç‚ºæ˜¯è©²é¡å‹
                logger.info(f"   ğŸ¯ åŒ¹é… {table_type}: {matches}/{len(headers)} å€‹æ¬„ä½")
                return table_type
        
        return 'general'  # æœªè­˜åˆ¥çš„ä¸€èˆ¬è¡¨æ ¼
    
    def _process_fuhsin_table(self, data: List[List], table_type: str) -> List[List]:
        """
        æ ¹æ“šç¦èˆˆè¡¨æ ¼ç‰¹æ€§é€²è¡Œè™•ç†
        
        å¸¸è¦‹å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆï¼š
        1. åˆä½µå„²å­˜æ ¼ï¼šPDF ä¸­æœƒè®Šæˆç©ºç™½æ ¼ï¼Œéœ€è¦å‘å‰å¡«å……
        2. å¤šè¡Œæ¨™é¡Œï¼šéœ€è¦åˆä½µæˆå–®ä¸€æ¨™é¡Œ
        3. ç©ºç™½è¡Œï¼šéœ€è¦éæ¿¾æ‰
        4. ç‰¹æ®Šå­—ç¬¦ï¼šéœ€è¦æ¸…ç†
        """
        processed = []
        
        for row_idx, row in enumerate(data):
            # æ¸…ç†æ¯å€‹å–®å…ƒæ ¼
            cleaned_row = []
            for col_idx, cell in enumerate(row):
                if cell is None:
                    # è™•ç†åˆä½µå„²å­˜æ ¼ï¼ˆå‘å·¦æˆ–å‘ä¸ŠæŸ¥æ‰¾ï¼‰
                    if col_idx > 0 and row[col_idx-1]:
                        cell = ''  # ä¿æŒç©ºç™½ï¼Œç¨å¾Œå¯èƒ½éœ€è¦åˆä½µ
                    elif row_idx > 0 and data[row_idx-1][col_idx]:
                        cell = ''  # å‚ç›´åˆä½µçš„æƒ…æ³
                    else:
                        cell = ''
                
                # æ¸…ç†æ–‡å­—
                cell = str(cell).strip()
                cell = re.sub(r'\s+', ' ', cell)  # å¤šå€‹ç©ºç™½åˆä½µç‚ºä¸€å€‹
                cell = cell.replace('\n', ' ')     # æ›è¡Œç¬¦æ›¿æ›ç‚ºç©ºæ ¼
                
                cleaned_row.append(cell)
            
            # éæ¿¾å…¨ç©ºç™½è¡Œ
            if any(cell for cell in cleaned_row):
                processed.append(cleaned_row)
        
        return processed
    
    def _create_dataframe(self, data: List[List], table_type: str) -> pd.DataFrame:
        """
        å»ºç«‹ DataFrame ä¸¦é€²è¡Œå¾Œè™•ç†
        
        ç‰¹æ®Šè™•ç†ï¼š
        1. è‡ªå‹•è­˜åˆ¥æ¨™é¡Œè¡Œ
        2. è¨­å®šæ­£ç¢ºçš„è³‡æ–™é¡å‹
        3. è™•ç†ç¼ºå¤±å€¼
        """
        if not data:
            return pd.DataFrame()
        
        # å‡è¨­ç¬¬ä¸€è¡Œæ˜¯æ¨™é¡Œ
        if len(data) > 1:
            df = pd.DataFrame(data[1:], columns=data[0])
        else:
            df = pd.DataFrame(data)
        
        # æ ¹æ“šè¡¨æ ¼é¡å‹é€²è¡Œç‰¹æ®Šè™•ç†
        if table_type == 'ecn':
            # è¨­è®Šé€šçŸ¥å–®ç‰¹æ®Šè™•ç†
            df = self._process_ecn_dataframe(df)
        elif table_type == 'spec':
            # ç”¢å“è¦æ ¼è¡¨ç‰¹æ®Šè™•ç†
            df = self._process_spec_dataframe(df)
        
        return df
    
    def _process_ecn_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """è™•ç†è¨­è®Šé€šçŸ¥å–® DataFrame"""
        # è­˜åˆ¥æ—¥æœŸæ¬„ä½ä¸¦è½‰æ›æ ¼å¼
        date_columns = df.columns[df.columns.str.contains('æ—¥æœŸ|æ™‚é–“', na=False)]
        for col in date_columns:
            df[col] = pd.to_datetime(df[col], errors='coerce', format='%Y/%m/%d')
        
        return df
    
    def _process_spec_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """è™•ç†ç”¢å“è¦æ ¼è¡¨ DataFrame"""
        # è­˜åˆ¥æ•¸å€¼æ¬„ä½
        numeric_columns = df.columns[df.columns.str.contains('æ•¸é‡|æ•¸å€¤|å…¬å·®', na=False)]
        for col in numeric_columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        
        return df
    
    def _extract_form_fields(self, page, page_num: int, results: Dict) -> Dict:
        """
        æ­¥é©Ÿ 3: æå–è¡¨å–®æ¬„ä½ï¼ˆéè¡¨æ ¼çš„çµæ§‹åŒ–è³‡æ–™ï¼‰
        
        åŸç†ï¼š
        ç¦èˆˆçš„æ–‡ä»¶å¸¸æœ‰é€™ç¨®æ ¼å¼ï¼š
        æ¬„ä½åç¨±ï¼šæ¬„ä½å€¼
        æˆ–
        â–¡ é¸é …1 â˜‘ é¸é …2 â–¡ é¸é …3
        """
        form_data = {}
        
        # å–å¾—é é¢æ‰€æœ‰æ–‡å­—
        text = page.extract_text()
        if not text:
            return form_data
        
        # æ¨¡å¼ 1: æ¨™ç±¤:å€¼ æ ¼å¼
        label_value_pattern = r'([^ï¼š:\n]+)[ï¼š:][\s]*([^ï¼š:\n]+)'
        matches = re.findall(label_value_pattern, text)
        
        for label, value in matches:
            label = label.strip()
            value = value.strip()
            
            # éæ¿¾æ‰å¤ªé•·çš„å…§å®¹ï¼ˆå¯èƒ½æ˜¯æ®µè½è€Œéæ¬„ä½ï¼‰
            if len(label) < 20 and len(value) < 100:
                form_data[label] = value
                logger.debug(f"   ğŸ“‹ è¡¨å–®æ¬„ä½: {label} = {value[:30]}...")
        
        # æ¨¡å¼ 2: æ ¸å–æ–¹å¡Š
        checkbox_pattern = r'[â–¡â˜‘]\s*([^â–¡â˜‘\n]+)'
        checkboxes = re.findall(checkbox_pattern, text)
        
        if checkboxes:
            form_data['checkboxes'] = checkboxes
            logger.debug(f"   â˜‘ æ ¸å–æ–¹å¡Š: {checkboxes}")
        
        # æ¨¡å¼ 3: ç¦èˆˆç‰¹å®šæ ¼å¼ - ç°½æ ¸æ¬„
        if 'ç°½æ ¸' in text or 'å¯©æ ¸' in text:
            approval_data = self._extract_approval_fields(text)
            if approval_data:
                form_data['approvals'] = approval_data
                logger.info(f"   ğŸ“ æ‰¾åˆ°ç°½æ ¸è³‡è¨Š: {len(approval_data)} ç­†")
        
        if form_data:
            results['forms'].append({
                'page': page_num,
                'fields': form_data
            })
        
        return form_data
    
    def _extract_approval_fields(self, text: str) -> List[Dict]:
        """
        æå–ç°½æ ¸æ¬„ä½
        ç¦èˆˆæ–‡ä»¶çš„ç°½æ ¸æ ¼å¼é€šå¸¸æ˜¯è¡¨æ ¼å¼çš„
        """
        approvals = []
        
        # ç°½æ ¸æ¨¡å¼ï¼šéƒ¨é–€/äººå“¡ + æ—¥æœŸ
        approval_pattern = r'(å“ä¿èª²|è£½é€ èª²|å€‰å„²èª²|[\u4e00-\u9fff]+èª²)[^0-9]*([\d/\-]+)'
        
        for dept, date in re.findall(approval_pattern, text):
            approvals.append({
                'department': dept,
                'date': date
            })
        
        return approvals
    
    def _extract_text_blocks(self, page, page_num: int, results: Dict) -> List[Dict]:
        """
        æ­¥é©Ÿ 4: æå–æ–‡å­—å€å¡Šï¼ˆæ®µè½æ–‡å­—ï¼‰
        
        ç”¨æ–¼æå–ï¼š
        - å•é¡Œæè¿°
        - æ”¹å–„èªªæ˜
        - å‚™è¨»å…§å®¹
        """
        text_blocks = []
        
        # ä½¿ç”¨ pdfplumber çš„ extract_text_lines å–å¾—æ›´ç²¾ç¢ºçš„æ–‡å­—ä½ç½®
        lines = page.extract_text_lines()
        
        current_block = []
        current_y = None
        
        for line in lines:
            # åˆ¤æ–·æ˜¯å¦ç‚ºæ–°æ®µè½ï¼ˆYåº§æ¨™å·®ç•°å¤§æ–¼é–¾å€¼ï¼‰
            if current_y is None:
                current_y = line['top']
                current_block = [line['text']]
            elif abs(line['top'] - current_y) > 20:  # æ–°æ®µè½
                if current_block:
                    block_text = ' '.join(current_block)
                    if len(block_text) > 50:  # åªä¿ç•™è¼ƒé•·çš„æ–‡å­—å€å¡Š
                        text_blocks.append({
                            'text': block_text,
                            'position': current_y
                        })
                current_block = [line['text']]
                current_y = line['top']
            else:
                current_block.append(line['text'])
        
        # è™•ç†æœ€å¾Œä¸€å€‹å€å¡Š
        if current_block:
            block_text = ' '.join(current_block)
            if len(block_text) > 50:
                text_blocks.append({
                    'text': block_text,
                    'position': current_y
                })
        
        if text_blocks:
            logger.info(f"   ğŸ“„ æ‰¾åˆ° {len(text_blocks)} å€‹æ–‡å­—å€å¡Š")
            results['text_blocks'].extend([{
                'page': page_num,
                **block
            } for block in text_blocks])
        
        return text_blocks
    
    def _explain_table_content(self, df: pd.DataFrame, table_type: str, results: Dict):
        """
        è§£é‡‹æå–çš„è¡¨æ ¼å…§å®¹
        """
        explanation = []
        
        if table_type == 'ecn':
            explanation.append("è¨­è®Šé€šçŸ¥å–®å…§å®¹ï¼š")
            if 'è¨­è®Šå‰' in df.columns and 'è¨­è®Šå¾Œ' in df.columns:
                for idx, row in df.iterrows():
                    explanation.append(f"  - è®Šæ›´é …ç›® {idx+1}:")
                    explanation.append(f"    è¨­è®Šå‰: {row.get('è¨­è®Šå‰', 'N/A')}")
                    explanation.append(f"    è¨­è®Šå¾Œ: {row.get('è¨­è®Šå¾Œ', 'N/A')}")
        
        elif table_type == 'spec':
            explanation.append("ç”¢å“è¦æ ¼è¡¨å…§å®¹ï¼š")
            if 'å“è™Ÿ' in df.columns:
                for idx, row in df.iterrows():
                    explanation.append(f"  - ç”¢å“: {row.get('å“è™Ÿ', 'N/A')}")
                    explanation.append(f"    è¦æ ¼: {row.get('è¦æ ¼', 'N/A')}")
        
        if explanation:
            results['extraction_log'].extend(explanation)
            for line in explanation:
                logger.info(line)


# ========== ä½¿ç”¨ç¯„ä¾‹ ==========
def demo_extraction():
    """
    ç¤ºç¯„å¦‚ä½•ä½¿ç”¨è§£æå™¨
    """
    extractor = DetailedPDFTableExtractor()
    
    # å‡è¨­æœ‰ä¸€å€‹ç¦èˆˆçš„ PDF æª”æ¡ˆ
    pdf_path = "EC-K-28-C-083.pdf"
    
    # åŸ·è¡Œè§£æ
    results = extractor.extract_with_detailed_explanation(pdf_path)
    
    # è¼¸å‡ºçµæœ
    print("\n" + "="*60)
    print("ğŸ“Š è§£æçµæœæ‘˜è¦")
    print("="*60)
    
    print(f"\næ‰¾åˆ° {len(results['tables'])} å€‹è¡¨æ ¼")
    for table in results['tables']:
        print(f"  - ç¬¬ {table['page']} é : {table['type']} è¡¨æ ¼ ({table['shape'][0]}x{table['shape'][1]})")
    
    print(f"\næ‰¾åˆ° {len(results['forms'])} å€‹è¡¨å–®")
    for form in results['forms']:
        print(f"  - ç¬¬ {form['page']} é : {len(form['fields'])} å€‹æ¬„ä½")
    
    print(f"\næ‰¾åˆ° {len(results['text_blocks'])} å€‹æ–‡å­—å€å¡Š")
    
    print("\nğŸ“ è§£æéç¨‹è¨˜éŒ„:")
    for log in results['extraction_log'][-10:]:  # é¡¯ç¤ºæœ€å¾Œ10æ¢
        print(f"  {log}")
    
    return results

if __name__ == "__main__":
    demo_extraction()
