#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å„ªåŒ–ç‰ˆ MySQL è‡ªå‹•å°å…¥æœå‹™
- æ”¯æ´å¤§å‹ SQL æª”æ¡ˆè™•ç†
- æ™ºèƒ½æ‰¹æ¬¡åŸ·è¡Œ
- äº¤æ˜“ç®¡ç†å’ŒéŒ¯èª¤æ¢å¾©
- é€²åº¦è¿½è¹¤
"""

import os, time, json, hashlib, logging, re, pymysql
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional, Tuple, Iterator
from pymysql.cursors import DictCursor

# ============== é…ç½® ==============
MYSQL_HOST = os.getenv("MYSQL_HOST", "mysql")
MYSQL_PORT = int(os.getenv("MYSQL_PORT", "3306"))
MYSQL_USER = os.getenv("MYSQL_USER", "root")
MYSQL_PASSWORD = os.getenv("MYSQL_PASSWORD", "root")
MYSQL_DATABASE = os.getenv("MYSQL_DATABASE", "fuhsin_erp_demo")

# ç›®éŒ„é…ç½®
WATCH_DIR = Path(os.getenv("SQL_WATCH_DIR", "/sql/incoming"))
DONE_DIR = WATCH_DIR / ".done"
ERROR_DIR = WATCH_DIR / ".error"
PROGRESS_DIR = WATCH_DIR / ".progress"
STATE_FILE = WATCH_DIR / ".import_state.json"
LOG_FILE = Path("/logs/importer/mysql_importer.log")

# æ•ˆèƒ½é…ç½®
SCAN_INTERVAL = int(os.getenv("SCAN_INTERVAL", "10"))
BATCH_SIZE = int(os.getenv("SQL_BATCH_SIZE", "1000"))      # æ¯æ‰¹åŸ·è¡Œçš„ INSERT æ•¸é‡
MAX_RETRY = int(os.getenv("MAX_RETRY", "3"))               # æœ€å¤§é‡è©¦æ¬¡æ•¸
CONNECTION_POOL_SIZE = int(os.getenv("POOL_SIZE", "5"))    # é€£ç·šæ± å¤§å°

# ============== æ—¥èªŒè¨­å®š ==============
os.makedirs(LOG_FILE.parent, exist_ok=True)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(LOG_FILE),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ============== é€£ç·šæ± ç®¡ç† ==============
class MySQLConnectionPool:
    """MySQL é€£ç·šæ± """
    
    def __init__(self, size: int = CONNECTION_POOL_SIZE):
        self.size = size
        self.connections = []
        self.used_connections = set()
        self._create_connections()
    
    def _create_connections(self):
        """å»ºç«‹é€£ç·šæ± """
        for _ in range(self.size):
            conn = self._create_connection()
            if conn:
                self.connections.append(conn)
    
    def _create_connection(self):
        """å»ºç«‹å–®ä¸€é€£ç·š"""
        try:
            conn = pymysql.connect(
                host=MYSQL_HOST,
                port=MYSQL_PORT,
                user=MYSQL_USER,
                password=MYSQL_PASSWORD,
                database=MYSQL_DATABASE,
                charset='utf8mb4',
                autocommit=False,
                cursorclass=DictCursor
            )
            return conn
        except Exception as e:
            logger.error(f"å»ºç«‹é€£ç·šå¤±æ•—: {e}")
            return None
    
    def get_connection(self):
        """å–å¾—å¯ç”¨é€£ç·š"""
        while self.connections:
            conn = self.connections.pop(0)
            try:
                # æª¢æŸ¥é€£ç·šæ˜¯å¦æœ‰æ•ˆ
                conn.ping(reconnect=True)
                self.used_connections.add(conn)
                return conn
            except:
                # é€£ç·šå¤±æ•ˆï¼Œå»ºç«‹æ–°é€£ç·š
                new_conn = self._create_connection()
                if new_conn:
                    self.used_connections.add(new_conn)
                    return new_conn
        
        # ç„¡å¯ç”¨é€£ç·šï¼Œç­‰å¾…æˆ–å»ºç«‹æ–°é€£ç·š
        if len(self.used_connections) < self.size:
            new_conn = self._create_connection()
            if new_conn:
                self.used_connections.add(new_conn)
                return new_conn
        
        raise Exception("ç„¡å¯ç”¨é€£ç·š")
    
    def return_connection(self, conn):
        """æ­¸é‚„é€£ç·š"""
        if conn in self.used_connections:
            self.used_connections.remove(conn)
            try:
                conn.rollback()  # ç¢ºä¿æ¸…ç†ç‹€æ…‹
                self.connections.append(conn)
            except:
                # é€£ç·šå·²æå£ï¼Œä¸æ”¾å›æ± ä¸­
                pass
    
    def close_all(self):
        """é—œé–‰æ‰€æœ‰é€£ç·š"""
        for conn in self.connections + list(self.used_connections):
            try:
                conn.close()
            except:
                pass
        self.connections.clear()
        self.used_connections.clear()

# å…¨åŸŸé€£ç·šæ± 
connection_pool = MySQLConnectionPool()

# ============== SQL è§£æå™¨ ==============
class SQLParser:
    """æ™ºèƒ½ SQL è§£æå™¨"""
    
    @staticmethod
    def parse_file(filepath: Path) -> Iterator[Tuple[str, str]]:
        """
        è§£æ SQL æª”æ¡ˆï¼Œè¿”å› (èªå¥é¡å‹, SQL) çš„è¿­ä»£å™¨
        æ”¯æ´å¤§æª”æ¡ˆä¸²æµè™•ç†
        """
        current_statement = []
        in_string = False
        string_char = None
        line_count = 0
        
        with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
            for line in f:
                line_count += 1
                
                # è·³éè¨»è§£å’Œç©ºè¡Œ
                stripped = line.strip()
                if not stripped or stripped.startswith('--') or stripped.startswith('#'):
                    continue
                
                # è™•ç†å¤šè¡Œ SQL
                i = 0
                while i < len(line):
                    char = line[i]
                    
                    # è™•ç†å­—ä¸²
                    if not in_string:
                        if char in ["'", '"', '`']:
                            in_string = True
                            string_char = char
                    else:
                        if char == string_char:
                            # æª¢æŸ¥æ˜¯å¦è½‰ç¾©
                            if i + 1 < len(line) and line[i + 1] == string_char:
                                i += 1  # è·³éè½‰ç¾©å­—å…ƒ
                            else:
                                in_string = False
                                string_char = None
                    
                    current_statement.append(char)
                    
                    # æª¢æŸ¥èªå¥çµæŸ
                    if not in_string and char == ';':
                        sql = ''.join(current_statement).strip()
                        if sql and sql != ';':
                            # åˆ¤æ–·èªå¥é¡å‹
                            sql_upper = sql.upper()
                            if sql_upper.startswith('INSERT'):
                                stmt_type = 'INSERT'
                            elif sql_upper.startswith('UPDATE'):
                                stmt_type = 'UPDATE'
                            elif sql_upper.startswith('DELETE'):
                                stmt_type = 'DELETE'
                            elif sql_upper.startswith('CREATE'):
                                stmt_type = 'CREATE'
                            elif sql_upper.startswith('DROP'):
                                stmt_type = 'DROP'
                            elif sql_upper.startswith('ALTER'):
                                stmt_type = 'ALTER'
                            else:
                                stmt_type = 'OTHER'
                            
                            yield (stmt_type, sql)
                        
                        current_statement = []
                    
                    i += 1
        
        # è™•ç†æœ€å¾Œä¸€å€‹èªå¥ï¼ˆå¦‚æœæ²’æœ‰åˆ†è™Ÿçµå°¾ï¼‰
        if current_statement:
            sql = ''.join(current_statement).strip()
            if sql:
                yield ('OTHER', sql)
        
        logger.info(f"ğŸ“„ è§£æå®Œæˆï¼Œå…± {line_count} è¡Œ")
    
    @staticmethod
    def optimize_insert(sql: str) -> List[str]:
        """
        å„ªåŒ– INSERT èªå¥ï¼Œå°‡å¤§æ‰¹é‡ INSERT åˆ†å‰²æˆå°æ‰¹æ¬¡
        """
        # æª¢æŸ¥æ˜¯å¦ç‚ºå¤šå€¼ INSERT
        pattern = r'INSERT\s+INTO\s+`?(\w+)`?\s*\([^)]+\)\s*VALUES\s*(.+);?$'
        match = re.match(pattern, sql, re.IGNORECASE | re.DOTALL)
        
        if not match:
            return [sql]
        
        table = match.group(1)
        values_part = match.group(2).rstrip(';')
        
        # åˆ†å‰² VALUES
        values_list = []
        current_value = []
        paren_count = 0
        in_string = False
        
        for char in values_part:
            if not in_string:
                if char == '(':
                    paren_count += 1
                elif char == ')':
                    paren_count -= 1
                elif char == "'":
                    in_string = True
            else:
                if char == "'" and (len(current_value) == 0 or current_value[-1] != '\\'):
                    in_string = False
            
            current_value.append(char)
            
            if paren_count == 0 and char == ')':
                values_list.append(''.join(current_value).strip())
                current_value = []
                # è·³éé€—è™Ÿå’Œç©ºæ ¼
                continue
        
        # åˆ†æ‰¹å»ºç«‹ INSERT èªå¥
        if len(values_list) <= BATCH_SIZE:
            return [sql]
        
        # å–å¾—æ¬„ä½åˆ—è¡¨
        columns_match = re.search(r'\(([^)]+)\)', sql)
        columns = columns_match.group(0) if columns_match else ''
        
        batches = []
        for i in range(0, len(values_list), BATCH_SIZE):
            batch_values = values_list[i:i + BATCH_SIZE]
            batch_sql = f"INSERT INTO `{table}` {columns} VALUES {','.join(batch_values)};"
            batches.append(batch_sql)
        
        logger.info(f"ğŸ”„ åˆ†å‰² INSERT ç‚º {len(batches)} æ‰¹ï¼Œæ¯æ‰¹æœ€å¤š {BATCH_SIZE} ç­†")
        return batches

# ============== é€²åº¦ç®¡ç† ==============
class ProgressTracker:
    """é€²åº¦è¿½è¹¤å™¨"""
    
    def __init__(self, filepath: Path):
        self.filepath = filepath
        self.progress_file = PROGRESS_DIR / f"{filepath.stem}.progress"
        self.progress = self.load_progress()
    
    def load_progress(self) -> Dict:
        """è¼‰å…¥é€²åº¦"""
        PROGRESS_DIR.mkdir(exist_ok=True)
        if self.progress_file.exists():
            with open(self.progress_file, 'r') as f:
                return json.load(f)
        return {
            'total_statements': 0,
            'processed_statements': 0,
            'success_count': 0,
            'error_count': 0,
            'last_position': 0,
            'errors': []
        }
    
    def save_progress(self):
        """å„²å­˜é€²åº¦"""
        with open(self.progress_file, 'w') as f:
            json.dump(self.progress, f, indent=2, default=str)
    
    def update(self, success: bool, error_msg: str = None):
        """æ›´æ–°é€²åº¦"""
        self.progress['processed_statements'] += 1
        if success:
            self.progress['success_count'] += 1
        else:
            self.progress['error_count'] += 1
            if error_msg:
                self.progress['errors'].append({
                    'statement': self.progress['processed_statements'],
                    'error': error_msg[:500],
                    'time': datetime.now().isoformat()
                })
        self.save_progress()
    
    def complete(self):
        """å®Œæˆè™•ç†"""
        if self.progress_file.exists():
            self.progress_file.unlink()

# ============== æª”æ¡ˆè™•ç† ==============
def get_file_hash(filepath: Path) -> str:
    """è¨ˆç®—æª”æ¡ˆ MD5"""
    md5 = hashlib.md5()
    with open(filepath, 'rb') as f:
        for chunk in iter(lambda: f.read(8192), b''):
            md5.update(chunk)
    return md5.hexdigest()

def load_state() -> Dict:
    """è¼‰å…¥è™•ç†ç‹€æ…‹"""
    if STATE_FILE.exists():
        with open(STATE_FILE, 'r') as f:
            return json.load(f)
    return {}

def save_state(state: Dict):
    """å„²å­˜è™•ç†ç‹€æ…‹"""
    with open(STATE_FILE, 'w') as f:
        json.dump(state, f, indent=2, default=str)

def move_file(src: Path, dst_dir: Path) -> Path:
    """ç§»å‹•æª”æ¡ˆ"""
    dst_dir.mkdir(parents=True, exist_ok=True)
    dst = dst_dir / src.name
    
    # é¿å…è¦†è“‹
    if dst.exists():
        timestamp = int(time.time())
        dst = dst_dir / f"{src.stem}_{timestamp}{src.suffix}"
    
    src.rename(dst)
    return dst

# ============== SQL åŸ·è¡Œ ==============
def execute_sql_batch(connection, statements: List[Tuple[str, str]], progress: ProgressTracker) -> Tuple[int, int]:
    """
    æ‰¹æ¬¡åŸ·è¡Œ SQL èªå¥
    è¿”å› (æˆåŠŸæ•¸, å¤±æ•—æ•¸)
    """
    success_count = 0
    error_count = 0
    
    with connection.cursor() as cursor:
        for stmt_type, sql in statements:
            try:
                # å° INSERT é€²è¡Œå„ªåŒ–
                if stmt_type == 'INSERT':
                    optimized_sqls = SQLParser.optimize_insert(sql)
                    for opt_sql in optimized_sqls:
                        cursor.execute(opt_sql)
                        connection.commit()
                        success_count += 1
                else:
                    cursor.execute(sql)
                    connection.commit()
                    success_count += 1
                
                progress.update(True)
                
                # æ¯ 100 å€‹æˆåŠŸèªå¥è¼¸å‡ºä¸€æ¬¡é€²åº¦
                if success_count % 100 == 0:
                    logger.info(f"âœ… å·²è™•ç† {success_count} å€‹èªå¥")
                    
            except Exception as e:
                connection.rollback()
                error_count += 1
                error_msg = str(e)[:200]
                logger.error(f"âŒ SQL åŸ·è¡Œå¤±æ•—: {error_msg}")
                progress.update(False, error_msg)
                
                # å¦‚æœéŒ¯èª¤å¤ªå¤šï¼Œåœæ­¢è™•ç†
                if error_count > 100:
                    logger.error("éŒ¯èª¤éå¤šï¼Œåœæ­¢è™•ç†")
                    break
    
    return success_count, error_count

def process_sql_file(filepath: Path) -> bool:
    """
    è™•ç†å–®ä¸€ SQL æª”æ¡ˆ
    è¿”å›æ˜¯å¦æˆåŠŸ
    """
    logger.info(f"ğŸ“ é–‹å§‹è™•ç†: {filepath.name}")
    
    # åˆå§‹åŒ–é€²åº¦è¿½è¹¤
    progress = ProgressTracker(filepath)
    
    # å–å¾—é€£ç·š
    connection = None
    try:
        connection = connection_pool.get_connection()
        
        # è§£æä¸¦åŸ·è¡Œ SQL
        statements = []
        total_statements = 0
        
        for stmt_type, sql in SQLParser.parse_file(filepath):
            total_statements += 1
            statements.append((stmt_type, sql))
            
            # æ‰¹æ¬¡åŸ·è¡Œ
            if len(statements) >= 100:
                success, errors = execute_sql_batch(connection, statements, progress)
                statements = []
                logger.info(f"æ‰¹æ¬¡å®Œæˆ: æˆåŠŸ {success}, å¤±æ•— {errors}")
        
        # åŸ·è¡Œå‰©é¤˜èªå¥
        if statements:
            success, errors = execute_sql_batch(connection, statements, progress)
            logger.info(f"æœ€å¾Œæ‰¹æ¬¡: æˆåŠŸ {success}, å¤±æ•— {errors}")
        
        # å®Œæˆè™•ç†
        progress.complete()
        
        total_success = progress.progress['success_count']
        total_errors = progress.progress['error_count']
        
        if total_errors == 0:
            logger.info(f"âœ… å®Œæˆ: æˆåŠŸåŸ·è¡Œ {total_success} å€‹èªå¥")
            return True
        else:
            logger.warning(f"âš ï¸ å®Œæˆ: æˆåŠŸ {total_success}, å¤±æ•— {total_errors}")
            return total_errors < total_success * 0.1  # éŒ¯èª¤ç‡å°æ–¼ 10% è¦–ç‚ºæˆåŠŸ
            
    except Exception as e:
        logger.error(f"âŒ è™•ç†å¤±æ•—: {e}", exc_info=True)
        return False
        
    finally:
        if connection:
            connection_pool.return_connection(connection)

# ============== ä¸»ç¨‹å¼ ==============
def wait_for_mysql(max_retries: int = 30) -> bool:
    """ç­‰å¾… MySQL å°±ç·’"""
    for i in range(max_retries):
        try:
            conn = connection_pool.get_connection()
            connection_pool.return_connection(conn)
            logger.info("âœ… MySQL é€£ç·šæˆåŠŸ")
            return True
        except Exception as e:
            if i < max_retries - 1:
                logger.info(f"â³ ç­‰å¾… MySQL å°±ç·’... ({i+1}/{max_retries})")
                time.sleep(2)
            else:
                logger.error(f"âŒ MySQL é€£ç·šå¤±æ•—: {e}")
                return False
    return False

def scan_and_process():
    """æƒæä¸¦è™•ç† SQL æª”æ¡ˆ"""
    # ç¢ºä¿ç›®éŒ„å­˜åœ¨
    WATCH_DIR.mkdir(parents=True, exist_ok=True)
    DONE_DIR.mkdir(parents=True, exist_ok=True)
    ERROR_DIR.mkdir(parents=True, exist_ok=True)
    
    # è¼‰å…¥ç‹€æ…‹
    state = load_state()
    
    # æƒææª”æ¡ˆ
    sql_files = sorted(WATCH_DIR.glob("*.sql"))
    
    for sql_file in sql_files:
        # æª¢æŸ¥æª”æ¡ˆå¤§å°
        file_size = sql_file.stat().st_size / (1024 * 1024)  # MB
        logger.info(f"ğŸ“¦ ç™¼ç¾æª”æ¡ˆ: {sql_file.name} ({file_size:.2f} MB)")
        
        # è¨ˆç®—æª”æ¡ˆé›œæ¹Š
        file_hash = get_file_hash(sql_file)
        file_key = sql_file.name
        
        # æª¢æŸ¥æ˜¯å¦å·²è™•ç†
        if file_key in state and state[file_key].get('hash') == file_hash:
            logger.info(f"â­ï¸ è·³éå·²è™•ç†: {sql_file.name}")
            move_file(sql_file, DONE_DIR)
            continue
        
        # è™•ç†æª”æ¡ˆ
        start_time = time.time()
        success = process_sql_file(sql_file)
        elapsed = time.time() - start_time
        
        # æ›´æ–°ç‹€æ…‹
        state[file_key] = {
            'hash': file_hash,
            'processed_at': datetime.now().isoformat(),
            'success': success,
            'elapsed_seconds': elapsed,
            'file_size_mb': file_size
        }
        save_state(state)
        
        # ç§»å‹•æª”æ¡ˆ
        if success:
            logger.info(f"âœ… è™•ç†æˆåŠŸï¼Œè€—æ™‚ {elapsed:.2f} ç§’")
            move_file(sql_file, DONE_DIR)
        else:
            logger.error(f"âŒ è™•ç†å¤±æ•—")
            move_file(sql_file, ERROR_DIR)
        
        # è™•ç†å¤§æª”æ¡ˆå¾Œæš«åœ
        if file_size > 10:  # å¤§æ–¼ 10MB
            logger.info("è™•ç†å¤§æª”æ¡ˆå¾Œæš«åœ 5 ç§’...")
            time.sleep(5)

def main():
    """ä¸»ç¨‹å¼"""
    logger.info("=" * 60)
    logger.info("ğŸš€ MySQL è‡ªå‹•å°å…¥æœå‹™å•Ÿå‹•")
    logger.info(f"ğŸ“ ç›£æ§ç›®éŒ„: {WATCH_DIR}")
    logger.info(f"ğŸ”„ æƒæé–“éš”: {SCAN_INTERVAL} ç§’")
    logger.info(f"ğŸ“¦ æ‰¹æ¬¡å¤§å°: {BATCH_SIZE}")
    logger.info("=" * 60)
    
    # ç­‰å¾… MySQL
    if not wait_for_mysql():
        logger.error("ç„¡æ³•é€£ç·šåˆ° MySQLï¼Œæœå‹™çµ‚æ­¢")
        return
    
    # ä¸»å¾ªç’°
    no_file_count = 0
    
    try:
        while True:
            try:
                # æƒæä¸¦è™•ç†æª”æ¡ˆ
                files_found = len(list(WATCH_DIR.glob("*.sql")))
                
                if files_found > 0:
                    logger.info(f"ğŸ” ç™¼ç¾ {files_found} å€‹ SQL æª”æ¡ˆ")
                    scan_and_process()
                    no_file_count = 0
                else:
                    no_file_count += 1
                    # å‹•æ…‹èª¿æ•´æƒæé–“éš”
                    sleep_time = min(SCAN_INTERVAL * (1 + no_file_count // 10), 60)
                    if no_file_count % 10 == 0:
                        logger.info(f"ğŸ’¤ ç„¡æ–°æª”æ¡ˆï¼Œç­‰å¾… {sleep_time} ç§’...")
                    time.sleep(sleep_time)
                    
            except Exception as e:
                logger.error(f"âŒ è™•ç†éŒ¯èª¤: {e}", exc_info=True)
                time.sleep(30)
                
    except KeyboardInterrupt:
        logger.info("â¹ï¸ æ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿï¼Œæ­£åœ¨é—œé–‰...")
    finally:
        connection_pool.close_all()
        logger.info("ğŸ‘‹ æœå‹™å·²åœæ­¢")

if __name__ == "__main__":
    main()
